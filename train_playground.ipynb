{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10792a1d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "from torch import Tensor, LongTensor\n",
    "from torch_geometric.nn import radius_graph\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from typing import Tuple\n",
    "from ase import Atoms\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QM9(root='./data')\n",
    "\n",
    "y_values = dataset.y\n",
    "\n",
    "# normalize y values along each column\n",
    "y_values = (y_values - y_values.mean(dim=0)) / y_values.std(dim=0)\n",
    "dataset._data.y = y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.85, 0.05, 0.1], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, 'data/splits/dataset.pt')\n",
    "torch.save(train_dataset, 'data/splits/train_dataset.pt')\n",
    "torch.save(val_dataset, 'data/splits/val_dataset.pt')\n",
    "torch.save(test_dataset, 'data/splits/test_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSmearing(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start: float = 0.0,\n",
    "        stop: float = 5.0,\n",
    "        num_gaussians: int = 50,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        offset = torch.linspace(start, stop, num_gaussians)\n",
    "        self.coeff = -0.5 / (offset[1] - offset[0]).item()**2\n",
    "        self.register_buffer('offset', offset)\n",
    "\n",
    "    def forward(self, dist: Tensor) -> Tensor:\n",
    "        dist = dist.view(-1, 1) - self.offset.view(1, -1)\n",
    "        return torch.exp(self.coeff * torch.pow(dist, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadiusInteractionGraph(torch.nn.Module):\n",
    "    r\"\"\"Creates edges based on atom positions :obj:`pos` to all points within\n",
    "    the cutoff distance.\n",
    "\n",
    "    Args:\n",
    "        cutoff (float, optional): Cutoff distance for interatomic interactions.\n",
    "            (default: :obj:`10.0`)\n",
    "        max_num_neighbors (int, optional): The maximum number of neighbors to\n",
    "            collect for each node within the :attr:`cutoff` distance with the\n",
    "            default interaction graph method.\n",
    "            (default: :obj:`32`)\n",
    "    \"\"\"\n",
    "    def __init__(self, cutoff: float = 10.0, max_num_neighbors: int = 32):\n",
    "        super().__init__()\n",
    "        self.cutoff = cutoff\n",
    "        self.max_num_neighbors = max_num_neighbors\n",
    "\n",
    "    def forward(self, pos: Tensor, batch: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            pos (Tensor): Coordinates of each atom.\n",
    "            batch (LongTensor, optional): Batch indices assigning each atom to\n",
    "                a separate molecule.\n",
    "\n",
    "        :rtype: (:class:`LongTensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "        edge_index = radius_graph(pos, r=self.cutoff, batch=batch,\n",
    "                                  max_num_neighbors=self.max_num_neighbors)\n",
    "        row, col = edge_index\n",
    "        edge_weight = (pos[row] - pos[col]).norm(dim=-1)\n",
    "        return edge_index, edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, heads, num_gaussians):\n",
    "        super().__init__()\n",
    "        # GATConv with edge features\n",
    "        self.conv = GATConv(\n",
    "            in_channels=num_features, \n",
    "            out_channels=num_targets,\n",
    "            heads=heads,\n",
    "            edge_dim=num_gaussians  # match your num_gaussians for edge attributes\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(num_targets * heads)\n",
    "        self.ff = nn.Linear(num_targets * heads, num_features)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, edge_attr):\n",
    "        # GATConv only needs x, edge_index, and edge_attr\n",
    "        out = self.conv(x, edge_index, edge_attr=edge_attr)\n",
    "        out = self.ln(out)\n",
    "        out = self.ff(out)\n",
    "        return x + out  # residual connection\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels: int = 128,\n",
    "        num_features: int = 11,\n",
    "        num_targets: int = 19,\n",
    "        heads: int = 8,\n",
    "        cutoff: float = 5.0,\n",
    "        max_num_neighbors: int = 32,\n",
    "        num_gaussians: int = 50,\n",
    "        num_blocks: int = 3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(100, hidden_channels, padding_idx=0)\n",
    "        self.interaction_graph = RadiusInteractionGraph(cutoff, max_num_neighbors)\n",
    "        self.distance_expansion = GaussianSmearing(0.0, cutoff, num_gaussians)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                AttentionBlock(hidden_channels, num_targets, heads, num_gaussians)\n",
    "                for _ in range(num_blocks)\n",
    "            ]\n",
    "        )\n",
    "        self.lin1 = nn.Linear(hidden_channels, hidden_channels // 2)\n",
    "        self.act = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(hidden_channels // 2, num_targets)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.embedding(data.z)\n",
    "        edge_index, edge_weight = self.interaction_graph(data.pos, data.batch)\n",
    "        edge_attr = self.distance_expansion(edge_weight)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = h + block(h, edge_index, edge_weight, edge_attr)\n",
    "\n",
    "        out = self.lin1(h)\n",
    "        out = self.act(out)\n",
    "        out = self.lin2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on one batch to test the model\n",
    "def train():\n",
    "    model.train()\n",
    "    # get first batch only\n",
    "    data = next(iter(train_loader))\n",
    "    optimizer.zero_grad()\n",
    "    # get node embeddings\n",
    "    node_embeddings = model(data)\n",
    "    # get graph embedding\n",
    "    out = global_mean_pool(node_embeddings, data.batch)\n",
    "    loss = criterion(out[:,7], data.y[:,7])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5363\n",
      "Epoch 2, Loss: 0.3657\n",
      "Epoch 3, Loss: 0.3409\n",
      "Epoch 4, Loss: 0.3845\n",
      "Epoch 5, Loss: 0.4619\n",
      "Epoch 6, Loss: 0.5015\n",
      "Epoch 7, Loss: 0.4844\n",
      "Epoch 8, Loss: 0.4412\n",
      "Epoch 9, Loss: 0.2549\n",
      "Epoch 10, Loss: 0.3926\n",
      "Epoch 11, Loss: 0.6556\n",
      "Epoch 12, Loss: 0.3610\n",
      "Epoch 13, Loss: 0.4893\n",
      "Epoch 14, Loss: 0.2691\n",
      "Epoch 15, Loss: 0.3302\n",
      "Epoch 16, Loss: 0.4661\n",
      "Epoch 17, Loss: 0.5319\n",
      "Epoch 18, Loss: 0.4192\n",
      "Epoch 19, Loss: 0.4921\n",
      "Epoch 20, Loss: 0.5398\n",
      "Epoch 21, Loss: 0.5813\n",
      "Epoch 22, Loss: 0.2633\n",
      "Epoch 23, Loss: 0.4397\n",
      "Epoch 24, Loss: 0.3027\n",
      "Epoch 25, Loss: 0.7000\n",
      "Epoch 26, Loss: 0.3932\n",
      "Epoch 27, Loss: 0.3514\n",
      "Epoch 28, Loss: 0.4299\n",
      "Epoch 29, Loss: 0.6667\n",
      "Epoch 30, Loss: 0.3789\n",
      "Epoch 31, Loss: 0.2189\n",
      "Epoch 32, Loss: 0.6897\n",
      "Epoch 33, Loss: 1.6795\n",
      "Epoch 34, Loss: 0.8366\n",
      "Epoch 35, Loss: 0.4885\n",
      "Epoch 36, Loss: 0.3352\n",
      "Epoch 37, Loss: 0.2558\n",
      "Epoch 38, Loss: 0.7270\n",
      "Epoch 39, Loss: 0.4491\n",
      "Epoch 40, Loss: 0.2835\n",
      "Epoch 41, Loss: 1.2102\n",
      "Epoch 42, Loss: 0.4246\n",
      "Epoch 43, Loss: 0.3800\n",
      "Epoch 44, Loss: 0.3658\n",
      "Epoch 45, Loss: 0.5966\n",
      "Epoch 46, Loss: 0.3569\n",
      "Epoch 47, Loss: 0.6606\n",
      "Epoch 48, Loss: 0.3906\n",
      "Epoch 49, Loss: 0.4842\n",
      "Epoch 50, Loss: 0.5915\n",
      "Epoch 51, Loss: 0.7022\n",
      "Epoch 52, Loss: 0.2001\n",
      "Epoch 53, Loss: 0.5426\n",
      "Epoch 54, Loss: 0.4760\n",
      "Epoch 55, Loss: 0.3003\n",
      "Epoch 56, Loss: 0.4669\n",
      "Epoch 57, Loss: 0.3117\n",
      "Epoch 58, Loss: 0.3326\n",
      "Epoch 59, Loss: 0.5274\n",
      "Epoch 60, Loss: 0.3678\n",
      "Epoch 61, Loss: 0.4534\n",
      "Epoch 62, Loss: 0.3063\n",
      "Epoch 63, Loss: 0.6234\n",
      "Epoch 64, Loss: 0.3309\n",
      "Epoch 65, Loss: 0.2993\n",
      "Epoch 66, Loss: 0.4580\n",
      "Epoch 67, Loss: 0.4424\n",
      "Epoch 68, Loss: 0.4297\n",
      "Epoch 69, Loss: 0.4166\n",
      "Epoch 70, Loss: 0.7936\n",
      "Epoch 71, Loss: 0.4341\n",
      "Epoch 72, Loss: 0.5598\n",
      "Epoch 73, Loss: 0.4291\n",
      "Epoch 74, Loss: 0.4035\n",
      "Epoch 75, Loss: 0.3650\n",
      "Epoch 76, Loss: 0.3881\n",
      "Epoch 77, Loss: 0.5159\n",
      "Epoch 78, Loss: 0.2367\n",
      "Epoch 79, Loss: 0.3618\n",
      "Epoch 80, Loss: 0.4068\n",
      "Epoch 81, Loss: 0.3992\n",
      "Epoch 82, Loss: 0.7690\n",
      "Epoch 83, Loss: 0.3222\n",
      "Epoch 84, Loss: 0.4041\n",
      "Epoch 85, Loss: 0.6253\n",
      "Epoch 86, Loss: 0.3407\n",
      "Epoch 87, Loss: 0.2763\n",
      "Epoch 88, Loss: 0.4776\n",
      "Epoch 89, Loss: 0.2721\n",
      "Epoch 90, Loss: 0.3815\n",
      "Epoch 91, Loss: 0.2594\n",
      "Epoch 92, Loss: 0.5686\n",
      "Epoch 93, Loss: 0.3967\n",
      "Epoch 94, Loss: 0.4726\n",
      "Epoch 95, Loss: 0.3984\n",
      "Epoch 96, Loss: 0.4545\n",
      "Epoch 97, Loss: 0.6374\n",
      "Epoch 98, Loss: 0.5534\n",
      "Epoch 99, Loss: 0.5289\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    loss = train()\n",
    "    print(f'Epoch {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    total_loss = 0  \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data.x, data.edge_index)\n",
    "            out = global_mean_pool(out, data.batch)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
